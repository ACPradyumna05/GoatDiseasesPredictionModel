# -*- coding: utf-8 -*-
"""GoatDisease.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dCNaFTgi2CNhVlxVhwVRCBtgHe1oayYW
"""

import matplotlib as plt
import numpy as np
import pandas as pd
import sklearn as sk
import scipy as sp
import matplotlib.pyplot as plt

print("Hello World!")

import os
import cv2
import xml.etree.ElementTree as ET
import numpy as np
from tensorflow.keras.utils import to_categorical
from sklearn.model_selection import train_test_split
from google.colab import drive
drive.mount('/content/drive')

BASE_PATH = "/content/drive/MyDrive/GraphEThon/AnnotatedDataset"
DERMATITIS_IMG_PATH = os.path.join(BASE_PATH, "ActualImages/CNF_Dermatitis")
PPR_IMG_PATH = os.path.join(BASE_PATH, "ActualImages/CNF_PPR")
HEALTHY_IMG_PATH = os.path.join(BASE_PATH, "Healthy")

DERMATITIS_ANNOTATIONS_PATH = os.path.join(BASE_PATH, "DermatitisAnnotated/Annotations")
PPR_ANNOTATIONS_PATH = os.path.join(BASE_PATH, "PPRDataset/Annotations")


def parse_voc_annotation(xml_file, img_folder):
    tree = ET.parse(xml_file)
    root = tree.getroot()

    filename = root.find("filename").text
    img_path = os.path.join(img_folder, filename)
    objects = []
    for obj in root.findall("object"):
        label = obj.find("name").text
        bbox = obj.find("bndbox")
        xmin = int(float(bbox.find("xmin").text))
        ymin = int(float(bbox.find("ymin").text))
        xmax = int(float(bbox.find("xmax").text))
        ymax = int(float(bbox.find("ymax").text))

        objects.append({"label": label, "bbox": (xmin, ymin, xmax, ymax)})

    return img_path, objects


test_xml_file = os.path.join(DERMATITIS_ANNOTATIONS_PATH, "DSC08973.xml")
img_path, objects = parse_voc_annotation(test_xml_file, DERMATITIS_IMG_PATH)

print(f"Image: {img_path}")
print(f"Objects: {objects}")

from google.colab.patches import cv2_imshow
import cv2
import numpy as np
import tensorflow as tf
from sklearn.model_selection import train_test_split
from tensorflow.keras.utils import to_categorical

def crop_annotated_regions(img_path, objects):
    img = cv2.imread(img_path)

    if img is None:
        print(f"Error: Unable to load image {img_path}")
        return [], []

    cropped_regions = []
    labels = []

    for obj in objects:
        xmin, ymin, xmax, ymax = map(int, obj["bbox"])
        xmin, ymin = max(0, xmin), max(0, ymin)
        xmax, ymax = min(img.shape[1] - 1, xmax), min(img.shape[0] - 1, ymax)

        cropped = img[ymin:ymax, xmin:xmax]
        if cropped.size == 0:
            print(f"Warning: Skipping invalid crop {obj['bbox']} in {img_path}")
            continue

        if len(cropped.shape) == 2:
            cropped = cv2.cvtColor(cropped, cv2.COLOR_GRAY2RGB)

        cropped = cv2.resize(cropped, (128, 128))
        cropped_regions.append(cropped)
        labels.append(obj["label"])

    return cropped_regions, labels

cropped_images, labels = crop_annotated_regions(img_path, objects)


if cropped_images:
    cv2_imshow(cropped_images[0])
else:
    print("No valid cropped images to display.")

def load_dataset():
    all_images = []
    all_labels = []


    for xml_file in os.listdir(DERMATITIS_ANNOTATIONS_PATH):
        if not xml_file.endswith(".xml"):
            continue
        img_path, objects = parse_voc_annotation(os.path.join(DERMATITIS_ANNOTATIONS_PATH, xml_file), DERMATITIS_IMG_PATH)
        cropped_images, labels = crop_annotated_regions(img_path, objects)
        all_images.extend(cropped_images)
        all_labels.extend(labels)


    for xml_file in os.listdir(PPR_ANNOTATIONS_PATH):
        if not xml_file.endswith(".xml"):
            continue
        img_path, objects = parse_voc_annotation(os.path.join(PPR_ANNOTATIONS_PATH, xml_file), PPR_IMG_PATH)
        cropped_images, labels = crop_annotated_regions(img_path, objects)
        all_images.extend(cropped_images)
        all_labels.extend(labels)


    for img_file in os.listdir(HEALTHY_IMG_PATH):
        if img_file.endswith((".jpg", ".png")):
            img_path = os.path.join(HEALTHY_IMG_PATH, img_file)
            img = cv2.imread(img_path)
            if img is not None:
                img = cv2.resize(img, (128, 128))
                all_images.append(img)
                all_labels.append("Healthy")

    return all_images, all_labels

cropped_images, labels = load_dataset()

if len(cropped_images) == 0 or len(labels) == 0:
    print("Error: No valid data found. Please check dataset and annotations.")
else:

    X = np.array(cropped_images, dtype=np.float32) / 255.0
    y_labels = np.array(labels)


    unique_labels = sorted(set(y_labels))
    label_to_index = {label: idx for idx, label in enumerate(unique_labels)}
    y = np.array([label_to_index[label] for label in y_labels])


    y = to_categorical(y, num_classes=len(unique_labels))


    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

    print(f"Dataset loaded successfully! Shapes:")
    print(f"X_train: {X_train.shape}, y_train: {y_train.shape}")
    print(f"X_val: {X_val.shape}, y_val: {y_val.shape}")

import matplotlib.pyplot as plt
import random

def check_random_images(X, y, label_to_index):
    index_to_label = {v: k for k, v in label_to_index.items()}

    random_indices = random.sample(range(len(X)), min(5, len(X)))

    plt.figure(figsize=(15, 3))
    for i, idx in enumerate(random_indices):
        plt.subplot(1, 5, i + 1)
        plt.imshow(X[idx])
        plt.axis("off")
        label_index = np.argmax(y[idx])
        plt.title(f"Label: {index_to_label[label_index]}")

    plt.show()


check_random_images(X, y, label_to_index)

import tensorflow as tf
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.layers import Dense, Flatten, Dropout, GlobalAveragePooling2D
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping

base_model = MobileNetV2(weights="imagenet", include_top=False, input_shape=(128, 128, 3))


base_model.trainable = False


x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dense(128, activation="relu")(x)
x = Dropout(0.3)(x)
output_layer = Dense(len(label_to_index), activation="softmax")(x)

model = Model(inputs=base_model.input, outputs=output_layer)


model.compile(optimizer=Adam(learning_rate=0.0001), loss="categorical_crossentropy", metrics=["accuracy"])

early_stopping = EarlyStopping(monitor="val_loss", patience=5, restore_best_weights=True)


history = model.fit(
    X_train, y_train,
    validation_data=(X_val, y_val),
    epochs=20,
    batch_size=32,
    callbacks=[early_stopping]
)


val_loss, val_acc = model.evaluate(X_val, y_val)
print(f"Validation Accuracy: {val_acc:.4f}")

from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np

y_pred_probs = model.predict(X_val)
y_pred = np.argmax(y_pred_probs, axis=1)
y_true = np.argmax(y_val, axis=1)


print("Classification Report:\n")
print(classification_report(y_true, y_pred, target_names=label_to_index.keys()))


conf_matrix = confusion_matrix(y_true, y_pred)


plt.figure(figsize=(6, 5))
sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="Blues", xticklabels=label_to_index.keys(), yticklabels=label_to_index.keys())
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.title("Confusion Matrix")
plt.show()

def test_model_on_image(image_path, model, label_to_index):

    img = cv2.imread(image_path)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    img = cv2.resize(img, (128, 128))
    img = img / 255.0
    img = np.expand_dims(img, axis=0)


    prediction = model.predict(img)
    predicted_class = np.argmax(prediction)


    index_to_label = {v: k for k, v in label_to_index.items()}
    predicted_label = index_to_label[predicted_class]


    plt.imshow(cv2.imread(image_path)[:, :, ::-1])
    plt.axis("off")
    plt.title(f"Predicted: {predicted_label}")
    plt.show()

    return predicted_label

sample_image_path = "/content/drive/MyDrive/GraphEThon/AnnotatedDataset/SampleImage/Derma1.jpg"
predicted_label = test_model_on_image(sample_image_path, model, label_to_index)
print(f"Predicted Label: {predicted_label}")

